# aiaugmentation_evaluation

The aiaugmentation_evaluation contains software to manually evaluate requirements. Requirements are either semantically identical (j), semantically different (n) or exact duplicates (d). The software provides interaction via the terminal and tracks the evaluation that is done. 
The results from the experiments are located in the folder data and placed in subfolders according to their experiment. In order to evaluate specific experiment data, the file needs to be extracted from the subfolder and placed on parent level (output folder).

## Quick install

Navigate to the "aiaugmentation_evaluation" folder

conda was chosen as package manager, create a conda environment as following:

```cmd
conda env create --file environment.yml
```

Necessary packages are included in the environment.yml and should be installed automatically.

activate the conda envrionment as shown here:

```cmd
conda activate aiaugmentation_experimentENV
```

## Getting started

This software was developed for evaluating the experiment for AIAugmentation-Bachelor-Thesis-2023

Some methods are included to support the evaluation of the samples generated by the main aiaugmentation software. 

You can access cli-methods by typing: python cli.py -m "METHOD" -i "INPUT"

to find out which methods are available, type: python cli.py -h

The method evaluate_experiment requires you to pass a file as an argument. The file should be placed in data/output, as this directory will be scanned for your file.
Just pass the filename with extension (e.g. "text.json"), the algorithm will take care of the rest.

after conducting an experiment, the result will be placed inside data/output/evaluated
the method calc_evaluate_experiment takes a filename with extension as an input and will search through this directory to find the coresponding file.